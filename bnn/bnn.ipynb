{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058c20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pyro\n",
    "from pyro.infer.mcmc import MCMC\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from kernel.sghmc import SGHMC\n",
    "from kernel.sgld import SGLD\n",
    "from kernel.sgd import SGD\n",
    "from kernel.sgnuts import NUTS as SGNUTS\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b6cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.data))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af08685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "NUM_EPOCHS = 800\n",
    "WARMUP_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f96971",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('./data', train=True, download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True)\n",
    "\n",
    "perm = torch.randperm(len(train_dataset))\n",
    "train_idx = perm[:len(train_dataset)*5//6]\n",
    "val_idx = perm[len(train_dataset)*5//6:]\n",
    "    \n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "\n",
    "# scale and normalise the datasets\n",
    "X_train = train_dataset.data[train_idx] / 255.0\n",
    "Y_train = train_dataset.targets[train_idx]\n",
    "\n",
    "X_val = train_dataset.data[val_idx] / 255.0 \n",
    "Y_val = train_dataset.targets[val_idx]\n",
    "\n",
    "X_test = (test_dataset.data / 255.0 - mean) / std\n",
    "Y_test = test_dataset.targets\n",
    "\n",
    "# redefine the datasets\n",
    "train_dataset = Dataset(X_train, Y_train)\n",
    "val_dataset = Dataset(X_val, Y_val)\n",
    "test_dataset = Dataset(X_test, Y_test)\n",
    "\n",
    "# setup the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883e2552",
   "metadata": {},
   "outputs": [],
   "source": [
    "PyroLinear = pyro.nn.PyroModule[torch.nn.Linear]\n",
    "    \n",
    "class BNN(pyro.nn.PyroModule):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, prec=1.):\n",
    "        super().__init__()\n",
    "        # prec is a kwarg that should only used by SGD to set the regularization strength \n",
    "        # recall that a Guassian prior over the weights is equivalent to L2 norm regularization in the non-Bayes setting\n",
    "        \n",
    "        # TODO add gamma priors to precision terms\n",
    "        self.fc1 = PyroLinear(input_size, hidden_size)\n",
    "        self.fc1.weight = pyro.nn.PyroSample(dist.Normal(0., prec).expand([hidden_size, input_size]).to_event(2))\n",
    "        self.fc1.bias   = pyro.nn.PyroSample(dist.Normal(0., prec).expand([hidden_size]).to_event(1))\n",
    "        \n",
    "        self.fc2 = PyroLinear(hidden_size, output_size)\n",
    "        self.fc2.weight = pyro.nn.PyroSample(dist.Normal(0., prec).expand([output_size, hidden_size]).to_event(2))\n",
    "        self.fc2.bias   = pyro.nn.PyroSample(dist.Normal(0., prec).expand([output_size]).to_event(1))\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.log_softmax(x)# output (log) softmax probabilities of each class\n",
    "        \n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(logits=x), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f463b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Warmup:   0%|                                                                                    | 0/100 [00:00, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26784/3249555965.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mWARMUP_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0msgnuts_mcmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mWARMUP_EPOCHS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bml\\lib\\site-packages\\pyro\\poutine\\messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[1;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bml\\lib\\site-packages\\pyro\\infer\\mcmc\\api.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[1;31m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchain_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mnum_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bml\\lib\\site-packages\\pyro\\infer\\mcmc\\api.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_logger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mhook_w_logging\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_add_logging_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             for sample in _gen_samples(\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bml\\lib\\site-packages\\pyro\\infer\\mcmc\\api.py\u001b[0m in \u001b[0;36m_gen_samples\u001b[1;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m         )\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         hook(\n\u001b[0;32m    160\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\MSc Oxford\\ATML\\project\\repo\\bnn\\..\\kernel\\sgnuts.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    468\u001b[0m                     \u001b[0mz_right_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz_right_grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# go the the left, start from the left leaf of current tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m                     new_tree = self._build_tree(\n\u001b[0m\u001b[0;32m    471\u001b[0m                         \u001b[0mz_left\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                         \u001b[0mr_left\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\MSc Oxford\\ATML\\project\\repo\\bnn\\..\\kernel\\sgnuts.py\u001b[0m in \u001b[0;36m_build_tree\u001b[1;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[0;32m    262\u001b[0m     ):\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtree_depth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             return self._build_basetree(\n\u001b[0m\u001b[0;32m    265\u001b[0m                 \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menergy_current\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             )\n",
      "\u001b[1;32m~\\OneDrive\\MSc Oxford\\ATML\\project\\repo\\bnn\\..\\kernel\\sgnuts.py\u001b[0m in \u001b[0;36m_build_basetree\u001b[1;34m(self, z, r, z_grads, log_slice, direction, energy_current)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mr_new_unscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[0menergy_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpotential_energy\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkinetic_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_new_unscaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;31m# handle the NaN case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\MSc Oxford\\ATML\\project\\repo\\bnn\\..\\kernel\\sgnuts.py\u001b[0m in \u001b[0;36munscale\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0msite_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0msite_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0msite_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msite_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "LR = 2e-6\n",
    "MOMENTUM_DECAY = 0.01\n",
    "NUM_STEPS = 1\n",
    "\n",
    "bnn = BNN(28*28, 100, 10)\n",
    "\n",
    "sgnuts = SGNUTS(bnn,\n",
    "              subsample_positions=[0, 1],\n",
    "              batch_size=BATCH_SIZE,\n",
    "              learning_rate=LR,\n",
    "              momentum_decay=MOMENTUM_DECAY,\n",
    "              with_friction=True,\n",
    "              obs_info_noise=False)\n",
    "\n",
    "sgnuts_mcmc = MCMC(sgnuts, num_samples=len(train_dataset)//BATCH_SIZE, warmup_steps=0)\n",
    "# full posterior predictive \n",
    "full_predictive = torch.FloatTensor(10000, 10)\n",
    "full_predictive.zero_()\n",
    "\n",
    "for epoch in range(1+NUM_EPOCHS + WARMUP_EPOCHS):\n",
    "    sgnuts_mcmc.run(X_train, Y_train)\n",
    "    \n",
    "    if epoch >= WARMUP_EPOCHS:\n",
    "        \n",
    "        sgnuts_samples = sgnuts_mcmc.get_samples()\n",
    "        predictive = pyro.infer.Predictive(bnn, posterior_samples=sgnuts_samples)\n",
    "        start = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_predictive = None\n",
    "            for x, y in val_loader:\n",
    "                if epoch_predictive is None:\n",
    "                    epoch_predictive = predictive(x)['obs'].to(torch.int8)\n",
    "                else:\n",
    "                    epoch_predictive = torch.cat((epoch_predictive, predictive(x)['obs'].to(torch.int8)), dim=1)\n",
    "                    \n",
    "            for sample in epoch_predictive:\n",
    "                predictive_one_hot = F.one_hot(sample, num_classes=10)\n",
    "                full_predictive = full_predictive + predictive_one_hot\n",
    "                \n",
    "            full_y_hat = torch.argmax(full_predictive, dim=1)\n",
    "            total = Y_val.shape[0]\n",
    "            correct = int((full_y_hat == Y_val).sum())\n",
    "            \n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Epoch [{}/{}] test accuracy: {:.4f} time: {:.2f}\".format(epoch-WARMUP_EPOCHS, NUM_EPOCHS, correct/total, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-6\n",
    "MOMENTUM_DECAY = 0.01\n",
    "NUM_STEPS = 1\n",
    "\n",
    "bnn = BNN(28*28, 100, 10)\n",
    "\n",
    "sghmc = SGHMC(bnn,\n",
    "              subsample_positions=[0, 1],\n",
    "              batch_size=BATCH_SIZE,\n",
    "              learning_rate=LR,\n",
    "              momentum_decay=MOMENTUM_DECAY,\n",
    "              num_steps=NUM_STEPS)\n",
    "\n",
    "sghmc_mcmc = MCMC(sghmc, num_samples=len(train_dataset)//BATCH_SIZE, warmup_steps=0)\n",
    "# full posterior predictive \n",
    "full_predictive = torch.FloatTensor(10000, 10)\n",
    "full_predictive.zero_()\n",
    "\n",
    "for epoch in range(1+NUM_EPOCHS + WARMUP_EPOCHS):\n",
    "    sghmc_mcmc.run(X_train, Y_train)\n",
    "    \n",
    "    if epoch >= WARMUP_EPOCHS:\n",
    "        \n",
    "        sghmc_samples = sghmc_mcmc.get_samples()\n",
    "        predictive = pyro.infer.Predictive(bnn, posterior_samples=sghmc_samples)\n",
    "        start = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_predictive = None\n",
    "            for x, y in val_loader:\n",
    "                if epoch_predictive is None:\n",
    "                    epoch_predictive = predictive(x)['obs'].to(torch.int8)\n",
    "                else:\n",
    "                    epoch_predictive = torch.cat((epoch_predictive, predictive(x)['obs'].to(torch.int8)), dim=1)\n",
    "                    \n",
    "            for sample in epoch_predictive:\n",
    "                predictive_one_hot = F.one_hot(sample, num_classes=10)\n",
    "                full_predictive = full_predictive + predictive_one_hot\n",
    "                \n",
    "            full_y_hat = torch.argmax(full_predictive, dim=1)\n",
    "            total = Y_val.shape[0]\n",
    "            correct = int((full_y_hat == Y_val).sum())\n",
    "            \n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Epoch [{}/{}] test accuracy: {:.4f} time: {:.2f}\".format(epoch-WARMUP_EPOCHS, NUM_EPOCHS, correct/total, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902568b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-5\n",
    "NOISE_RATE = 4e-5\n",
    "NUM_STEPS = 1\n",
    "\n",
    "bnn = BNN(28*28, 100, 10)\n",
    "\n",
    "sgld = SGLD(bnn,\n",
    "            subsample_positions=[0, 1],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            learning_rate=LR,\n",
    "            noise_rate=NOISE_RATE,\n",
    "            num_steps=NUM_STEPS)\n",
    "\n",
    "sgld_mcmc = MCMC(sgld, num_samples=len(train_dataset)//BATCH_SIZE, warmup_steps=0)\n",
    "# full posterior predictive \n",
    "full_predictive = torch.FloatTensor(10000, 10)\n",
    "full_predictive.zero_()\n",
    "\n",
    "for epoch in range(1+NUM_EPOCHS + WARMUP_EPOCHS):\n",
    "    sgld_mcmc.run(X_train, Y_train)\n",
    "    sgld_samples = sgld_mcmc.get_samples()\n",
    "    \n",
    "    if epoch >= WARMUP_EPOCHS:\n",
    "        \n",
    "        start = time.time()\n",
    "        sgld_samples = sgld_mcmc.get_samples()\n",
    "        predictive = pyro.infer.Predictive(bnn, posterior_samples=sgld_samples)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_predictive = None\n",
    "            for x, y in val_loader:\n",
    "                if epoch_predictive is None:\n",
    "                    epoch_predictive = predictive(x)['obs'].to(torch.int64)\n",
    "                else:\n",
    "                    epoch_predictive = torch.cat((epoch_predictive, predictive(x)['obs'].to(torch.int64)), dim=1)\n",
    "            \n",
    "            for sample in epoch_predictive:\n",
    "                predictive_one_hot = F.one_hot(sample, num_classes=10)\n",
    "                full_predictive = full_predictive + predictive_one_hot\n",
    "                \n",
    "            full_y_hat = torch.argmax(full_predictive, dim=1)\n",
    "            total = Y_val.shape[0]\n",
    "            correct = int((full_y_hat == Y_val).sum())\n",
    "            \n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Epoch [{}/{}] test accuracy: {:.4f} time: {:.2f}\".format(epoch-WARMUP_EPOCHS, NUM_EPOCHS, correct/total, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "WEIGHT_DECAY=0.000002\n",
    "WITH_MOMENTUM=True\n",
    "MOMENTUM_DECAY=0.01\n",
    "REGULARIZATION_TERM=0.1\n",
    "\n",
    "bnn = BNN(28*28, 100, 10, prec=REGULARIZATION_TERM)\n",
    "\n",
    "sgd = SGD(bnn,\n",
    "          subsample_positions=[0, 1],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          learning_rate=LR,\n",
    "          weight_decay=WEIGHT_DECAY,\n",
    "          with_momentum=WITH_MOMENTUM,\n",
    "          momentum_decay=MOMENTUM_DECAY)\n",
    "\n",
    "sgd_mcmc = MCMC(sgd, num_samples=len(train_dataset)//BATCH_SIZE, warmup_steps=0)\n",
    "\n",
    "for epoch in range(1+NUM_EPOCHS):\n",
    "    sgd_mcmc.run(X_train, Y_train)\n",
    "        \n",
    "    if epoch >= 0:\n",
    "        \n",
    "        sgd_samples = sgd_mcmc.get_samples()\n",
    "        point_estimate = {site : sgd_samples[site][-1, :].unsqueeze(0) for site in sgd_samples.keys()}\n",
    "        predictive = pyro.infer.Predictive(bnn, posterior_samples=point_estimate)\n",
    "        start = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for x, y in val_loader:\n",
    "                batch_predictive = predictive(x)['obs']\n",
    "                batch_y_hat = batch_predictive.mode(0)[0]\n",
    "                total += y.shape[0]\n",
    "                correct += int((batch_y_hat == y).sum())\n",
    "            \n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Epoch [{}/{}] test accuracy: {:.4f} time: {:.2f}\".format(epoch-WARMUP_EPOCHS, NUM_EPOCHS, correct/total, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435107d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
